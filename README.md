# Portfolio

## Projects:
**[Remote Access Attacks Report:](https://github.com/kyleashburn/remote_access_attacks)**
In this project, I analyzed Windows log files from my desktop looking at attempts to use the remote desktop protocol to log into my computer. I started with an 8gb log file that wasn't formatted in a useful way and transformed it into a roughly 800 mb json that I then used for my analysis. I focused on questions about where the attacks were coming from and the like. Mostly just a data analytics project.

**[Database Design Project:](https://github.com/kyleashburn/Database-Project---Sinclair)**
In this project I completed as a final project for a database class at my community college, I constructed an Oracle database that was focused on being the backend of a hypothetical website meant to aid in the job search process/process of filling jobs. I built the entire database up from scratch and included triggers, views, and stored procedures. It is filled with dummy data but I still ran some queries on it to illustrate the functionality of the design.


**[Wikipedia & Covid-19:](https://github.com/kyleashburn/Wikipedia-Covid)**
In this project I completed as a project in a python data anlysis class, I examined Wikipedia data to see how trends of articles visits worked over time early on during the pandemic. I compared visits to the Covid-19 Pandemic and Covid-19 disease articles. I also compared the visits to comparable articles over the same time frame (SARS, MERS, H1N1) and the English language articles to French and Italian language articles. Finally, I compared completely neutral articles to the articles related to Covid to see if there were any similar visitation patterns. One of the challenges I faced was the inconsistency of the article titles (relating to Covid) over the time I was studying them. 

**[Rbnb:](https://github.com/kyleashburn/Rbnb)**
In this project I completed as a project in an information analytics class, I worked in R and Orange Rapid Miner to try to tease out informative attributes of success for a listing. I was hoping I could tease out the actions that a listing owner could take to be successful. I did my cleaning in R and made a decision tree, SVM, Na√Øve Bayes, & Logistic Regression model in Orange Rapid Miner which achieved between 67% and 70% accuracy. Ultimately, I didn't feel the models were terribly helpful for my goal and I probably would better off just examining the data. My biggest challenge I faced here was the data format changed on me while I was working on the project. 

**[Wayback Automation:](https://github.com/kyleashburn/Wayback_scraping)** In this quick project, I worked to automate the process of pulling captures from the wayback machine from a specific url. I went from conceptualization to execution in 24 hours and I was trying to help a friend with their masters research. 
It relies on the CDX API from the Wayback Machine in combination with the requests library to determine the scope of urls to scrape. For the actual scraping, I use pdfkit for the htm files on captured by Wayback and requests to pull the pdfs and docs captured by Wayback. My biggest challenge was understanding the way everything fit together in the CDX API.

**[PRC Embassy Text Mining:](https://github.com/kyleashburn/PRC_Embassy_Text_Mining)** 
In this long-term project, I've been working to build off my Wayback Automation project by running some simple text mining on the releases I'm pulling. I've been examining the title and body lengths of press releases and their sentiment by ambassador in office. Currently, I'm working to extend it by running topic modeling on the corpus of releases.

**[Peering Into Parler - Masters Paper:](https://github.com/kyleashburn/Peering-into-Parler---Masters-Paper)**
This is the github repo for my masters paper. It relies on work I did back in the Fall of 2021 and builds on it. This work is primarly focused on term frequency and topic modeling (LDA) in Python. In the hopes of reducing the stress on my fellow researchers, I did **not** spend substantial time cleaning up my code beyond what I had when I was doing my work. Thus, while I realize this may not be the perfect example for my portfolio, I feel the benefits to others outweight the costs to myself. 

**[Tableau - UNC Faculty Diversity:](https://github.com/kyleashburn/UNC-Faculty-Diversity---Tableau)**
This project was a midterm project in my information visualization class. In this project, I pulled data from a few PDFs using Python and then used that data to make a series of visualizations to clear up what the state of UNC faculty diversity is. 

**[Tableau - UNC System Salaries:](https://github.com/kyleashburn/UNC-System-Salaries---Tableau)**
This project was a final project in my information visualization class. In this project, I provide visualizations that enable both a high level overview of the state of salaries as well as a more granular view looking at just UNC Chapel Hill. 

**["A Practical Guide to Evil" End to End Project:](https://github.com/kyleashburn/PG2E)**
An end to end Python (in progress)  project scraping a WordPress serial novel series with scrapy. Post-scraping, analysis on a number of axes was conducted including topic modeling with LDA (among other techniques), sentiment analysis, NER, periodicity analysis, and other textual analysis on the novel chapters as well as comments left on each chapter.

